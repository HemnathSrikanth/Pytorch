{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e8aceb4",
   "metadata": {},
   "source": [
    "## 00 PyTorch Fundamentals\n",
    "\n",
    "[Documentation](https://www.learnpytorch.io/)\n",
    "[Github](https://github.com/mrdbourke/pytorch-deep-learning/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d3b55d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e6a0e25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.6.0+cu126'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e7b080a",
   "metadata": {},
   "source": [
    "## Scalar - zero dimension just single number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "acdb5f21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(7)\n",
      "7\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "scalar = torch.tensor(7)\n",
    "print(scalar)\n",
    "print(scalar.item()) # only work with scalar\n",
    "print(scalar.ndim) #no of dimensions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c333dcb",
   "metadata": {},
   "source": [
    "# Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cdfe31e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([7, 7])\n",
      "1\n",
      "torch.Size([2])\n"
     ]
    }
   ],
   "source": [
    "#Tensor takes only takes one argument so we need to pass multiple values as list and support only single data type just like array.\n",
    "vector = torch.tensor([7,7])\n",
    "print(vector)\n",
    "print(vector.ndim)\n",
    "print(vector.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "42da19d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 7,  8],\n",
      "        [ 9, 10],\n",
      "        [11, 12]])\n",
      "2\n",
      "torch.Size([3, 2])\n"
     ]
    }
   ],
   "source": [
    "MATRIX = torch.tensor([[7,8],\n",
    "                       [9,10],\n",
    "                       [11,12]])\n",
    "print(MATRIX)\n",
    "print(MATRIX.ndim)\n",
    "print(MATRIX.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "63b692a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1, 2, 3],\n",
      "         [4, 5, 6],\n",
      "         [7, 8, 9]]])\n"
     ]
    }
   ],
   "source": [
    "MATRIX = torch.tensor([[1,2,3],\n",
    "                       [4,5,6],\n",
    "                       [7,8,9]])\n",
    "TENSOR = torch.tensor([[[1,2,3],\n",
    "                        [4,5,6],\n",
    "                        [7,8,9]]])\n",
    "print(TENSOR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8c49dc0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.6014, 0.8261, 0.1146, 0.7396],\n",
      "        [0.6940, 0.0600, 0.3670, 0.4350],\n",
      "        [0.9001, 0.9625, 0.0104, 0.8893]])\n",
      "torch.float32\n"
     ]
    }
   ],
   "source": [
    "#Random Tensor\n",
    "random_tensor = torch.rand(size=(3,4))\n",
    "print(random_tensor)\n",
    "print(random_tensor.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d4c83b79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[9.9344e-01, 9.2996e-01, 6.4399e-01,  ..., 4.2444e-01,\n",
      "          4.1043e-01, 9.4939e-01],\n",
      "         [4.2675e-01, 3.3688e-01, 5.0589e-03,  ..., 8.9129e-02,\n",
      "          3.7795e-01, 9.0876e-01],\n",
      "         [8.0909e-01, 6.2921e-01, 8.9517e-01,  ..., 9.2712e-01,\n",
      "          8.9692e-01, 9.3149e-01],\n",
      "         ...,\n",
      "         [3.7555e-01, 3.6154e-01, 2.3698e-01,  ..., 7.1312e-01,\n",
      "          2.4707e-01, 5.4632e-01],\n",
      "         [1.9212e-01, 5.6399e-01, 2.8006e-01,  ..., 6.6688e-01,\n",
      "          5.4347e-01, 2.7273e-02],\n",
      "         [9.2931e-01, 7.5552e-01, 8.9210e-01,  ..., 2.0988e-01,\n",
      "          8.8649e-01, 9.6090e-01]],\n",
      "\n",
      "        [[6.9025e-01, 6.7428e-02, 9.4168e-01,  ..., 2.1554e-01,\n",
      "          4.0498e-02, 7.0000e-01],\n",
      "         [2.5154e-01, 4.1677e-01, 8.1003e-01,  ..., 8.3311e-01,\n",
      "          4.8956e-01, 9.9231e-01],\n",
      "         [6.7576e-01, 3.3368e-01, 1.0858e-01,  ..., 7.8002e-01,\n",
      "          6.0651e-01, 1.0258e-01],\n",
      "         ...,\n",
      "         [7.5913e-01, 7.0019e-02, 8.9258e-04,  ..., 1.0186e-01,\n",
      "          3.7880e-01, 2.6151e-03],\n",
      "         [7.4031e-01, 9.7414e-01, 7.1195e-01,  ..., 2.2459e-01,\n",
      "          1.8670e-01, 7.2152e-01],\n",
      "         [5.0949e-01, 1.9831e-01, 8.5867e-01,  ..., 1.2247e-01,\n",
      "          4.2483e-01, 8.6480e-01]],\n",
      "\n",
      "        [[2.0901e-01, 9.6156e-01, 2.5671e-01,  ..., 1.8890e-01,\n",
      "          4.9103e-01, 2.6813e-01],\n",
      "         [6.3866e-01, 1.1284e-01, 5.2622e-01,  ..., 9.6224e-01,\n",
      "          7.7289e-01, 3.3256e-01],\n",
      "         [9.9376e-01, 1.7678e-02, 4.1117e-01,  ..., 6.6606e-01,\n",
      "          1.9980e-01, 7.6883e-01],\n",
      "         ...,\n",
      "         [9.2990e-01, 4.2552e-01, 3.1160e-01,  ..., 6.1248e-01,\n",
      "          9.9758e-02, 5.5618e-01],\n",
      "         [1.2429e-01, 9.6278e-01, 7.6584e-02,  ..., 5.5611e-01,\n",
      "          9.0213e-01, 8.7459e-01],\n",
      "         [5.8363e-01, 2.2386e-01, 4.7306e-01,  ..., 1.9817e-01,\n",
      "          7.6238e-01, 3.9466e-02]]])\n"
     ]
    }
   ],
   "source": [
    "#Create a random tensor of size(224,224,3)\n",
    "random_image_size_tensor = torch.rand(size=(3,224,224))\n",
    "random_image_size_tensor.shape,random_image_size_tensor.ndim\n",
    "print(random_image_size_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9b8ceeef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.]]),\n",
       " torch.float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#zeros and ones\n",
    "zeros = torch.zeros(size=(3,4))\n",
    "zeros,zeros.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "35ae7f77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.]]),\n",
       " torch.float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ones = torch.ones(size=(3,4))\n",
    "ones,ones.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d7b7436",
   "metadata": {},
   "source": [
    "## Torch range and Tensors like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f1264cf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\srika\\AppData\\Local\\Temp\\ipykernel_23784\\734641592.py:2: UserWarning: torch.range is deprecated and will be removed in a future release because its behavior is inconsistent with Python's range builtin. Instead, use torch.arange, which produces values in [start, end).\n",
      "  zero_to_ten_deprecated = torch.range(0,10) #Note: this may return error in the future versions\n"
     ]
    }
   ],
   "source": [
    "# use torch.arange(), and torch.range() is depricated\n",
    "zero_to_ten_deprecated = torch.range(0,10) #Note: this may return error in the future versions\n",
    "\n",
    "#Create a range of value 0 to 10\n",
    "zero_to_ten = torch.arange(start=0,end=10,step=1)\n",
    "print(zero_to_ten)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4686af34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n"
     ]
    }
   ],
   "source": [
    "#Some times you might want one tensor of a certain type with the same shape as another tensor.\n",
    "#For example, a tensor of all zeros with the same shape as a previous tensor.\n",
    "\n",
    "ten_zeros = torch.zeros_like(input=zero_to_ten)\n",
    "print(ten_zeros)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef78296d",
   "metadata": {},
   "source": [
    "## Tensor datatypes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "337ca32d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3]), torch.float32, device(type='cpu'))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dtype defaults to None, which is torch.float32 or whatever datatype is passed.\n",
    "#device defaults to None, which uses the default tensor type.\n",
    "#if requires_grad is True, operations performed on the tensor are recorded.\n",
    "float_32_tensor = torch.tensor([3.0,6.0,9.0],dtype=None,device=None,requires_grad=False)\n",
    "float_32_tensor.shape,float_32_tensor.dtype,float_32_tensor.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9d0b79f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float16\n"
     ]
    }
   ],
   "source": [
    "float_16_tensor = torch.tensor([3.0,6.0,9.0],dtype=torch.float16) # torch.half would also work\n",
    "print(float_16_tensor.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "59bbada8",
   "metadata": {},
   "outputs": [],
   "source": [
    "float_32_tensor = torch.tensor([3.0,6.0,9.0],dtype=None,device=\"cuda\",requires_grad=False)\n",
    "float_16_tensor = torch.tensor([3.0,6.0,9.0],dtype=torch.float16,device=\"cuda\",requires_grad=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7122d726",
   "metadata": {},
   "source": [
    "## Getting information from tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1515ec40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3., 6., 9.], device='cuda:0') tensor([3., 6., 9.], device='cuda:0', dtype=torch.float16)\n",
      "Shape of tensor: torch.Size([3]), torch.Size([3])\n",
      "Datatype of tensor: torch.float32,torch.float16\n",
      "Device tensor is stored on: cuda:0, cuda:0\n"
     ]
    }
   ],
   "source": [
    "print(float_32_tensor,float_16_tensor)\n",
    "print(f\"Shape of tensor: {float_32_tensor.shape}, {float_16_tensor.shape}\")\n",
    "print(f\"Datatype of tensor: {float_32_tensor.dtype},{float_16_tensor.dtype}\")\n",
    "print(f\"Device tensor is stored on: {float_32_tensor.device}, {float_16_tensor.device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "37c950fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.7857, 0.9457, 0.8463, 0.3303],\n",
      "        [0.2750, 0.0563, 0.3631, 0.6921],\n",
      "        [0.1836, 0.6602, 0.4464, 0.0040]])\n",
      "Shape of tensor: torch.Size([3, 4])\n",
      "Datatype of tensor: torch.float32\n",
      "Device tensor is stored on: cpu\n"
     ]
    }
   ],
   "source": [
    "#create a tensor\n",
    "some_tensor = torch.rand(3,4)\n",
    "#Find out details about it\n",
    "print(some_tensor)\n",
    "print(f\"Shape of tensor: {some_tensor.shape}\")\n",
    "print(f\"Datatype of tensor: {some_tensor.dtype}\")\n",
    "print(f\"Device tensor is stored on: {some_tensor.device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c951451d",
   "metadata": {},
   "source": [
    "### Floating Point"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "b500e0a2",
   "metadata": {},
   "source": [
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ed4a3f41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.int64, torch.float16, torch.float64, torch.bfloat16)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f32  = torch.tensor([3,224,224]) #Defualt datatype\n",
    "f16  = torch.tensor([3,224,224],dtype=torch.float16)\n",
    "f64  = torch.tensor([3,224,224],dtype=torch.float64)\n",
    "bf16 = torch.tensor([3,224,224],dtype=torch.bfloat16)\n",
    "\n",
    "f32.dtype,f16.dtype,f64.dtype,bf16.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "79ab9362",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([9.0000e+00, 5.0176e+04, 5.0176e+04], dtype=torch.float16)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f32*f16"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41b1751b",
   "metadata": {},
   "source": [
    "#### Alternate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c426b4de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([  3., 224., 224.], dtype=torch.float16),\n",
       " tensor([  3., 224., 224.], dtype=torch.bfloat16),\n",
       " tensor([  3., 224., 224.]),\n",
       " tensor([  3., 224., 224.], dtype=torch.float64))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#CPU Tensor\n",
    "f16  = torch.HalfTensor([3,224,224])\n",
    "bf16 = torch.BFloat16Tensor([3,224,224])\n",
    "f32  = torch.FloatTensor([3,224,224])\n",
    "f64  = torch.DoubleTensor([3,224,224])\n",
    "\n",
    "f16,bf16,f32,f64\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f280ffd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\srika\\AppData\\Local\\Temp\\ipykernel_23784\\3423206018.py:2: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\torch\\csrc\\tensor\\python_tensor.cpp:80.)\n",
      "  f16  = torch.cuda.HalfTensor([3,224,224])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([  3., 224., 224.], device='cuda:0', dtype=torch.float16),\n",
       " tensor([  3., 224., 224.], device='cuda:0', dtype=torch.bfloat16),\n",
       " tensor([  3., 224., 224.], device='cuda:0'),\n",
       " tensor([  3., 224., 224.], device='cuda:0', dtype=torch.float64))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#GPU Tensor\n",
    "f16  = torch.cuda.HalfTensor([3,224,224])\n",
    "bf16 = torch.cuda.BFloat16Tensor([3,224,224])\n",
    "f32  = torch.cuda.FloatTensor([3,224,224])\n",
    "f64  = torch.cuda.DoubleTensor([3,224,224])\n",
    "\n",
    "# At first use it triggered warning to don't use this method when cuda is used and recommended the device=\"cuda\" method.\n",
    "\n",
    "f16,bf16,f32,f64"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b8c0ca8",
   "metadata": {},
   "source": [
    "### Integer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c5663d45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.int8, torch.int16, torch.int32, torch.int64)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Signed Integer - The range is from negative to positive\n",
    "i8  = torch.tensor([3,127,127],dtype=torch.int8)# its signed dtype so the range is -128 to 127\n",
    "i16 = torch.tensor([3,224,224],dtype=torch.int16)\n",
    "i32 = torch.tensor([3,224,224],dtype=torch.int32)\n",
    "i64 = torch.tensor([3,224,224],dtype=torch.int64)\n",
    "\n",
    "i8.dtype,i16.dtype,i32.dtype,i64.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d12b9b16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.uint8, torch.uint16, torch.uint32, torch.uint64)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Unsigned Integer - The range is from zero to positive or negative\n",
    "ui8  = torch.tensor([3,255,255],dtype=torch.uint8)#its unsigned so the range is 0 to 255 or -255\n",
    "ui16 = torch.tensor([3,224,224],dtype=torch.uint16)\n",
    "ui32 = torch.tensor([3,224,224],dtype=torch.uint32)\n",
    "ui64 = torch.tensor([3,224,224],dtype=torch.uint64)\n",
    "\n",
    "ui8.dtype,ui16.dtype,ui32.dtype,ui64.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01ccd357",
   "metadata": {},
   "source": [
    "#### Alternate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6723f53b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([  3, 127, 127], dtype=torch.int8),\n",
       " tensor([  3, 224, 224], dtype=torch.int16),\n",
       " tensor([  3, 224, 224], dtype=torch.int32),\n",
       " tensor([  3, 224, 224]),\n",
       " tensor([255], dtype=torch.uint8))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#CPU Tensor\n",
    "\n",
    "#Signed\n",
    "i8  = torch.CharTensor([3,127,127])\n",
    "i16 = torch.ShortTensor([3,224,224])\n",
    "i32 = torch.IntTensor([3,224,224])\n",
    "i64 = torch.LongTensor([3,224,224])\n",
    "\n",
    "#Unsigned\n",
    "ui8 = torch.ByteTensor([255])\n",
    "\n",
    "i8,i16,i32,i64,ui8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ef9a8359",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([  3, 127, 127], device='cuda:0', dtype=torch.int8),\n",
       " tensor([  3, 224, 224], device='cuda:0', dtype=torch.int16),\n",
       " tensor([  3, 224, 224], device='cuda:0', dtype=torch.int32),\n",
       " tensor([  3, 224, 224], device='cuda:0'),\n",
       " tensor([  3, 255, 255], device='cuda:0', dtype=torch.uint8))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#GPU Tensor\n",
    "\n",
    "#Signed\n",
    "i8 = torch.cuda.CharTensor([3,127,127])\n",
    "i16 = torch.cuda.ShortTensor([3,224,224])\n",
    "i32 = torch.cuda.IntTensor([3,224,224])\n",
    "i64 = torch.cuda.LongTensor([3,224,224])\n",
    "\n",
    "#Unsinged\n",
    "ui8 = torch.cuda.ByteTensor([3,255,255])\n",
    "\n",
    "i8,i16,i32,i64,ui8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e7f0a5f",
   "metadata": {},
   "source": [
    "### Tensor Manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "955699c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([11, 12, 13])\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.tensor([1,2,3])\n",
    "tensor = tensor+10\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e469eac0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3])\n"
     ]
    }
   ],
   "source": [
    "tensor = tensor - 10\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b4227a9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([10, 20, 30])\n"
     ]
    }
   ],
   "source": [
    "tensor = tensor * 10\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cad948fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([100, 400, 900])\n"
     ]
    }
   ],
   "source": [
    "tensor = tensor ** 2\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9305ac78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 50, 200, 450])\n"
     ]
    }
   ],
   "source": [
    "tensor = tensor // 2\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ede68297",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 25., 100., 225.])\n"
     ]
    }
   ],
   "source": [
    "tensor = tensor / 2\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d9b83949",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([11, 12, 13])\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.tensor([1,2,3])\n",
    "tensor = torch.add(tensor,10) # unlike list methods we need to store that update in the variable\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "770752fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3])\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.sub(tensor,10)\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d49e2cce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([20, 40, 60])\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.mul(tensor,20)\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8858384b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 400, 1600, 3600])\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.pow(tensor,2)\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f324ff99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 40., 160., 360.])\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.div(tensor,10)\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "50657bd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 4., 16., 36.])\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.floor_divide(tensor,10)\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01c35fa6",
   "metadata": {},
   "source": [
    "### Matrix Multiplication"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a45ed78f",
   "metadata": {},
   "source": [
    "One of then most common operations in machine learning and deep learning algorithms(like neural networks) is matrix mulitiplication.\n",
    "PyTorch implements matrix multiplication functionality in the torch.matmul() method.\n",
    "The main two rules for matrix multiplication to remember are:\n",
    "\n",
    "1. The inner dimensions must match:\n",
    "- (3,2) @ (3,2) won't work\n",
    "- (2,3) @ (3,2) will work\n",
    "- (3,2) @ (2,3) will work\n",
    "\n",
    "2. The resulting matrix has the shape of the outer dimensions:\n",
    "- (2,3) @ (3,2) -> (2,2)\n",
    "- (3,2) @ (2,3) -> (3,3)\n",
    "\n",
    "**Note: \"@\" in Python is the symbol for matrix multiplication**\n",
    "\n",
    "**Resource: You can see all of the rules for matrix multiplication using `torch.matmul()` in the Pytorch documentation.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1f4e8a16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3])\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor([1,2,3])\n",
    "print(a.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec5ad180",
   "metadata": {},
   "source": [
    "| Operation                  | Calculation              | Code                   |\n",
    "| ---------------------------| -------------------------|------------------------|\n",
    "| Element-wise multiplication| `[1*1,2*2,3*3] = [1,4,9]`| `tensor * tensor`      |\n",
    "| Matrix multiplication      | `[1*1+2*2+3*3] = [14]`   | `tensor.matmul(tensor)`|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6333ad12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 4, 9])\n"
     ]
    }
   ],
   "source": [
    "#Element - wise matrix multiplication\n",
    "print(a*a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "99242501",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(14)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Matrix multiplication\n",
    "torch.matmul(a,a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a427898c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(14)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Can also use the '@' symbol for matrix multiplication, though not recommended.\n",
    "a@a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85874368",
   "metadata": {},
   "source": [
    "You can do matrix multiplication by hand but its not recommended.\n",
    "\n",
    "The in-built `torch.matmul()` method is faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ac2e861d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n",
      "tensor(14)\n",
      "CPU times: total: 0 ns\n",
      "Wall time: 999 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "a = [1,2,3]\n",
    "b = [1,2,3]\n",
    "value = 0\n",
    "for i in range(len(a)):\n",
    "    value += a[i]*b[i]\n",
    "\n",
    "print(value)\n",
    "\n",
    "a = torch.tensor([1,2,3])\n",
    "b = torch.tensor([1,2,3])\n",
    "# c = a @ b # Alternative Matrix Multiplication but not recommended.\n",
    "c = torch.matmul(a,b)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "25290775",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(14)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "a = torch.tensor([1,2,3])\n",
    "b = torch.tensor([1,2,3])\n",
    "torch.matmul(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3067482a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 1e+03 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[19, 22],\n",
       "        [43, 50]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "a = torch.tensor([[1,2],[3,4]])\n",
    "b = torch.tensor([[5,6],[7,8]])\n",
    "torch.matmul(a,b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7fd1be4",
   "metadata": {},
   "source": [
    "#### One of the most common errors is deep learning(shape errors)\n",
    "\n",
    "Because much of deep learning is multiplying and performing operations on matrices and matrices have a strict rule about what shapes and sizes can be combined, one of the most common errors you'll run into in deep learning is shape mismatches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d4d52a7d",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (3x2 and 3x2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[46], line 8\u001b[0m\n\u001b[0;32m      2\u001b[0m tensor_A \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([[\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m2\u001b[39m],\n\u001b[0;32m      3\u001b[0m                          [\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m4\u001b[39m],\n\u001b[0;32m      4\u001b[0m                          [\u001b[38;5;241m5\u001b[39m,\u001b[38;5;241m6\u001b[39m]], dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[0;32m      5\u001b[0m tensor_B \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([[\u001b[38;5;241m7\u001b[39m,\u001b[38;5;241m10\u001b[39m],\n\u001b[0;32m      6\u001b[0m                          [\u001b[38;5;241m8\u001b[39m,\u001b[38;5;241m11\u001b[39m],\n\u001b[0;32m      7\u001b[0m                          [\u001b[38;5;241m9\u001b[39m,\u001b[38;5;241m12\u001b[39m]], dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[1;32m----> 8\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmatmul\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor_A\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtensor_B\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (3x2 and 3x2)"
     ]
    }
   ],
   "source": [
    "#Shapes need to be in the right way\n",
    "tensor_A = torch.tensor([[1,2],\n",
    "                         [3,4],\n",
    "                         [5,6]], dtype=torch.float32)\n",
    "tensor_B = torch.tensor([[7,10],\n",
    "                         [8,11],\n",
    "                         [9,12]], dtype=torch.float32)\n",
    "torch.matmul(tensor_A,tensor_B)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d8dd372",
   "metadata": {},
   "source": [
    "We can make matrix multiplication work between `tensor_A` and `tensor_B` by making their inner dimension match.\n",
    "\n",
    "one of the ways to do this with a **transpose**(switching the dimensions of a given tensor).\n",
    "\n",
    "You can perform transposes in PyTorch using either:\n",
    "\n",
    "- `torch.transpose(input,dim0,dim1)` - where `input` is the desired tensor to transpose and `dim0` and `dim1` are the dimensions to be swapped.\n",
    "- `tensor.T` - where `tensor` is the desired tensor to transpose.\n",
    "\n",
    "Lets try the latter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "45169fb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2.],\n",
      "        [3., 4.],\n",
      "        [5., 6.]])\n",
      "tensor([[ 7., 10.],\n",
      "        [ 8., 11.],\n",
      "        [ 9., 12.]])\n"
     ]
    }
   ],
   "source": [
    "#view tensor_A and tensor_B\n",
    "print(tensor_A)\n",
    "print(tensor_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "88515236",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2.],\n",
      "        [3., 4.],\n",
      "        [5., 6.]])\n",
      "tensor([[ 7.,  8.,  9.],\n",
      "        [10., 11., 12.]])\n"
     ]
    }
   ],
   "source": [
    "#view tensor_A and tensor_B.T\n",
    "print(tensor_A)\n",
    "print(tensor_B.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "209c06a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original shapes: tensor_A = torch.Size([3, 2]), tensor_B = torch.Size([3, 2])\n",
      "New shapes: tensor_A = torch.Size([3, 2]) (same as above), tensor_B.T = torch.Size([2, 3])\n",
      "Multiplying: torch.Size([3, 2])*torch.Size([2, 3]) <- innner dimensions match\n",
      "Output:\n",
      "\n",
      "tensor([[ 27.,  30.,  33.],\n",
      "        [ 61.,  68.,  75.],\n",
      "        [ 95., 106., 117.]])\n",
      "\n",
      "Output shape: torch.Size([3, 3])\n"
     ]
    }
   ],
   "source": [
    "#The operation works when tensor_B is transposed\n",
    "print(f\"Original shapes: tensor_A = {tensor_A.shape}, tensor_B = {tensor_B.shape}\")\n",
    "print(f\"New shapes: tensor_A = {tensor_A.shape} (same as above), tensor_B.T = {tensor_B.T.shape}\")\n",
    "print(f\"Multiplying: {tensor_A.shape}*{tensor_B.T.shape} <- innner dimensions match\")\n",
    "print(f\"Output:\\n\")\n",
    "output = torch.matmul(tensor_A,tensor_B.T)\n",
    "print(output)\n",
    "print(f\"\\nOutput shape: {output.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "21db5cac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 27.,  30.,  33.],\n",
       "        [ 61.,  68.,  75.],\n",
       "        [ 95., 106., 117.]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#torch.mm is a shortcut for matmul\n",
    "torch.mm(tensor_A,tensor_B.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a2fb2ab",
   "metadata": {},
   "source": [
    "Without the transpose, the rules of matrix multiplication aren't fulfilled and we get an error like above.\n",
    "\n",
    "You can create your own matrix multiplication visuals like this at http://matrixmultiplication.xyz/.\n",
    "\n",
    "Note: A matrix multiplication like this is also referred to as the dot product of two matrices.\n",
    "\n",
    "Neural networks are full of matrix multiplications and dot products."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a61ad4f5",
   "metadata": {},
   "source": [
    "### Finding the min, max, mean, sum, etc(tensor aggregation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8460b33c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 1, 11, 21, 31, 41, 51, 61, 71, 81, 91])\n"
     ]
    }
   ],
   "source": [
    "#Create a tensor\n",
    "x = torch.arange(0,100,10)\n",
    "x = x+1\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f23ecc40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(1), tensor(1))"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#find the min\n",
    "torch.min(x),x.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b1cffe50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(91), tensor(91))"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#find the max\n",
    "torch.max(x),x.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b8a106de",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mean(): could not infer output dtype. Input dtype must be either a floating point or complex dtype. Got: Long",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[57], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#find the mean\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m,x\u001b[38;5;241m.\u001b[39mmean() \u001b[38;5;66;03m#typical dtype error. Some operations only possible in particular datatype.\u001b[39;00m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: mean(): could not infer output dtype. Input dtype must be either a floating point or complex dtype. Got: Long"
     ]
    }
   ],
   "source": [
    "#find the mean\n",
    "torch.mean(x),x.mean() #typical dtype error. Some operations only possible in particular datatype."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "5051c679",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(46.), tensor(46.))"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#find the mean\n",
    "torch.mean(x.type(torch.float32)),x.type(torch.float32).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "6cd6b25f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(460), tensor(460))"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#find the sum\n",
    "torch.sum(x),x.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a568a326",
   "metadata": {},
   "source": [
    "#### Find the posistional min and max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d47cb93e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 1, 11, 21, 31, 41, 51, 61, 71, 81, 91])\n"
     ]
    }
   ],
   "source": [
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "fb05de14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(9), tensor(9))"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#find the index of max element\n",
    "torch.argmax(x),x.argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "85304d19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0), tensor(0))"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#find the index of min element\n",
    "torch.argmin(x),x.argmin()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a8457d6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minmum element in x: 1\n",
      "maximum elememnt in x: 91\n"
     ]
    }
   ],
   "source": [
    "print(f\"minmum element in x: {x[torch.argmin(x)].item()}\")\n",
    "print(f\"maximum elememnt in x: {x[torch.argmax(x)].item()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b1b7161",
   "metadata": {},
   "source": [
    "### Reshaping, stacking, squeezing and unsqueezing tensors\n",
    "\n",
    "* Reshaping - Reshapes an input tensor to defined shape.\n",
    "* View - Return a view of an input tensor of certain shape but keep the same memory as the original tensor.\n",
    "* Stacking - Combine multiple tensors on top of each other (vstack) or side by side (hstack).\n",
    "* Squeeze - Removes all `1` dimensions from a tensor.\n",
    "* Unsqueeze - Add a `1` dimension to a target tensor.\n",
    "* Permute - Return  a view of the input with dimensions permuted (swapped) in a certain way.\n",
    "\n",
    "These are all useful to fix tensor issues."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f52e1769",
   "metadata": {},
   "source": [
    "Why do any of these?\n",
    "Because deep learning models (neural networks) are all about manipulation tensors in some way. And because of the rules of matrix multiplication, if you've got shape mismatches, you'll run into errors. These methods help you make sure the right elements of your tensors are mixing with the right elements of other tensors.\n",
    "\n",
    "Let's try them out.\n",
    "\n",
    "First, we'll create a tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "662df879",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1., 2., 3., 4., 5., 6., 7., 8., 9.]), torch.Size([9]))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Let's create a tensor\n",
    "import torch\n",
    "x = torch.arange(1.,10.)\n",
    "x,x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b36e3931",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "shape '[2, 7]' is invalid for input of size 9",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#Add an extra dimension\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m x_reshaped \u001b[38;5;241m=\u001b[39m \u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m7\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;66;03m# shape error\u001b[39;00m\n\u001b[0;32m      3\u001b[0m x_reshaped,x_reshaped\u001b[38;5;241m.\u001b[39mshape\n",
      "\u001b[1;31mRuntimeError\u001b[0m: shape '[2, 7]' is invalid for input of size 9"
     ]
    }
   ],
   "source": [
    "#Add an extra dimension\n",
    "x_reshaped = x.reshape(2,7)# shape error\n",
    "x_reshaped,x_reshaped.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4cecb79c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1.],\n",
       "         [2.],\n",
       "         [3.],\n",
       "         [4.],\n",
       "         [5.],\n",
       "         [6.],\n",
       "         [7.],\n",
       "         [8.],\n",
       "         [9.]]),\n",
       " torch.Size([9, 1]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_reshaped = x.reshape(9,1) #think in factors way. Others wise get error.\n",
    "x_reshaped,x_reshaped.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "01440c94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 2., 3., 4., 5., 6., 7., 8., 9.]]), torch.Size([1, 9]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_reshaped = x.reshape(1,9)\n",
    "x_reshaped,x_reshaped.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3bc0c598",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 2., 3.],\n",
       "         [4., 5., 6.],\n",
       "         [7., 8., 9.]]),\n",
       " torch.Size([3, 3]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_reshaped = x.reshape(3,3)\n",
    "x_reshaped,x_reshaped.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7388140f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 2., 3., 4., 5., 6., 7., 8., 9.]]), torch.Size([1, 9]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Change the view\n",
    "z = x.view(1,9)\n",
    "z,z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c1bfb583",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[5., 2., 3., 4., 5., 6., 7., 8., 9.]]),\n",
       " tensor([5., 2., 3., 4., 5., 6., 7., 8., 9.]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Changing z changes x (because a view of a tensor shares the same memory as the original input) aka mutable.\n",
    "z[:,0]=5\n",
    "z,x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2b9fa7d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5., 5., 5., 5.],\n",
       "        [2., 2., 2., 2.],\n",
       "        [3., 3., 3., 3.],\n",
       "        [4., 4., 4., 4.],\n",
       "        [5., 5., 5., 5.],\n",
       "        [6., 6., 6., 6.],\n",
       "        [7., 7., 7., 7.],\n",
       "        [8., 8., 8., 8.],\n",
       "        [9., 9., 9., 9.]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Stack tensors on top of tensors\n",
    "x_stacked = torch.stack([x,x,x,x],dim=1) #dim=1, dim=0\n",
    "x_stacked"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14517656",
   "metadata": {},
   "source": [
    "`torch.squeeze(input)` Squeezes `input` to remove all the dimensions with value 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab9965ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5., 2., 3.],\n",
       "        [4., 5., 6.],\n",
       "        [7., 8., 9.]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#torch.squeeze() - remove all single dimensions from a target tensor.\n",
    "x_reshaped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16651f01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous tensor: tensor([[5., 2., 3.],\n",
      "        [4., 5., 6.],\n",
      "        [7., 8., 9.]])\n",
      "Previous shape: torch.Size([3, 3])\n",
      "\n",
      "New tensor: tensor([[5., 2., 3.],\n",
      "        [4., 5., 6.],\n",
      "        [7., 8., 9.]])\n",
      "New shape: torch.Size([3, 3])\n"
     ]
    }
   ],
   "source": [
    "#torch.squeeze() - removes all single dimensions from a target tensor.\n",
    "print(f\"Previous tensor: {x_reshaped}\")\n",
    "print(f\"Previous shape: {x_reshaped.shape}\")\n",
    "\n",
    "#Remove extra dimensions from x_reshaped\n",
    "x_squeezed = x_reshaped.squeeze()\n",
    "print(f\"\\nNew tensor: {x_squeezed}\")\n",
    "print(f\"New shape: {x_squeezed.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff0576e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous target: tensor([[5., 2., 3.],\n",
      "        [4., 5., 6.],\n",
      "        [7., 8., 9.]])\n",
      "Previous shape: torch.Size([3, 3])\n",
      "\n",
      "New tensor: tensor([[[5., 2., 3.],\n",
      "         [4., 5., 6.],\n",
      "         [7., 8., 9.]]])\n",
      "New shape: torch.Size([1, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "#torch.unsqueeze() - adds a single dimension to a target tensor at a specific dim(dimension)\n",
    "print(f\"Previous target: {x_squeezed}\")\n",
    "print(f\"Previous shape: {x_squeezed.shape}\")\n",
    "\n",
    "#Add an extra dimension with unsqueeze\n",
    "x_unsqueezed = x_squeezed.unsqueeze(dim=0)\n",
    "print(f\"\\nNew tensor: {x_unsqueezed}\")\n",
    "print(f\"New shape: {x_unsqueezed.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0705f8a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 3])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_reshaped.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d0a1e7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5., 2., 3.],\n",
       "        [4., 5., 6.],\n",
       "        [7., 8., 9.]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_reshaped.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4cf0e17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 3])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_reshaped.squeeze().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79ef968c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous shape: torch.Size([224, 224, 3])\n",
      "New shape: torch.Size([3, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "# torch.permute - rearranges the dimensions of a target tensor in a specified order\n",
    "x_original = torch.rand(size=(224,224,3)) #[height,width,color_channels # the dimensions counted from 0\n",
    "#we have 3 dimensions here 224,224,3 so it becomes 0,1,2\n",
    "\n",
    "# Permute the original tensor to rearrange the axis (or dim) order.\n",
    "x_permuted = x_original.permute(2,0,1) #shifts axis 0->1, 1->2, 2->0\n",
    "\n",
    "print(f\"Previous shape: {x_original.shape}\")\n",
    "print(f\"New shape: {x_permuted.shape}\")# [color_channels, height, width]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c786e681",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[2.3094e+05, 5.0889e-01, 5.8530e-01],\n",
      "         [1.7348e-01, 9.5342e-01, 7.4408e-01],\n",
      "         [4.1048e-01, 2.4209e-01, 4.6233e-01],\n",
      "         ...,\n",
      "         [5.2864e-01, 3.7559e-01, 5.0635e-01],\n",
      "         [2.6533e-02, 9.5046e-01, 8.1433e-01],\n",
      "         [7.2038e-01, 3.0871e-01, 9.5890e-01]],\n",
      "\n",
      "        [[9.1616e-01, 8.3540e-01, 6.9949e-01],\n",
      "         [9.5810e-01, 7.3440e-01, 9.7432e-01],\n",
      "         [3.3344e-01, 4.7178e-01, 3.9595e-01],\n",
      "         ...,\n",
      "         [9.8824e-01, 8.5818e-02, 7.1709e-01],\n",
      "         [4.8343e-02, 5.5665e-01, 9.9558e-01],\n",
      "         [6.2684e-01, 3.9626e-01, 2.6743e-01]],\n",
      "\n",
      "        [[8.3327e-01, 6.3802e-01, 2.7520e-02],\n",
      "         [5.9913e-01, 2.6958e-01, 8.4740e-01],\n",
      "         [7.6398e-01, 6.7103e-01, 2.8693e-02],\n",
      "         ...,\n",
      "         [9.8376e-02, 3.8695e-01, 2.2484e-01],\n",
      "         [9.6326e-01, 7.4155e-01, 5.6390e-01],\n",
      "         [5.0211e-02, 3.1871e-01, 3.2404e-01]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[2.6600e-01, 9.9707e-01, 6.7196e-01],\n",
      "         [7.4936e-01, 4.4237e-01, 1.6388e-01],\n",
      "         [2.9361e-01, 4.1413e-01, 6.0228e-01],\n",
      "         ...,\n",
      "         [7.2722e-02, 5.2374e-01, 6.1943e-01],\n",
      "         [8.2554e-02, 2.2341e-02, 9.4232e-01],\n",
      "         [5.0536e-01, 5.9473e-01, 2.5701e-01]],\n",
      "\n",
      "        [[5.6499e-02, 6.2737e-01, 8.2117e-01],\n",
      "         [9.7305e-01, 7.3893e-01, 8.4865e-01],\n",
      "         [5.5023e-01, 3.2185e-01, 5.3068e-01],\n",
      "         ...,\n",
      "         [4.2520e-01, 5.4301e-01, 3.6798e-01],\n",
      "         [8.3373e-01, 1.4652e-01, 8.8123e-01],\n",
      "         [2.9165e-01, 4.5570e-01, 3.7785e-02]],\n",
      "\n",
      "        [[1.4659e-01, 8.0123e-01, 4.6725e-01],\n",
      "         [9.6041e-01, 8.1988e-01, 8.2032e-01],\n",
      "         [8.8071e-01, 5.1598e-01, 7.6029e-01],\n",
      "         ...,\n",
      "         [1.1386e-01, 4.3822e-01, 6.6890e-01],\n",
      "         [4.8517e-01, 6.0748e-01, 1.3309e-01],\n",
      "         [4.0284e-01, 4.1255e-01, 9.3490e-01]]])\n"
     ]
    }
   ],
   "source": [
    "x_original[0,0,0] = 230943\n",
    "print(x_original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa03f5de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(230943.), tensor(230943.))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_original[0,0,0],x_permuted[0,0,0] # permute use view(), and view() shares the same memory if we use view() or permute() it can affect the original data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "485b7b92",
   "metadata": {},
   "source": [
    "### Indexing (selecting data from tensors)\n",
    "Indexing with PyTorch is similar to indexing with NumPy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "78fd2d84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[1, 2, 3],\n",
       "          [4, 5, 6],\n",
       "          [7, 8, 9]]]),\n",
       " torch.Size([1, 3, 3]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a tensor\n",
    "import torch\n",
    "x = torch.arange(1,10).reshape(1,3,3)\n",
    "x,x.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f968a655",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3],\n",
       "        [4, 5, 6],\n",
       "        [7, 8, 9]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Let's index on our new tensor\n",
    "x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec39d910",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Let's index on the middle bracket (dim=1)\n",
    "x[0][0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6045f6cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Let's index on the most inner bracket (last dimension)\n",
    "x[0][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd460347",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(9)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0][2][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12a02ef6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3])\n",
      "tensor([[1, 2, 3]])\n"
     ]
    }
   ],
   "source": [
    "print(x[0][0])\n",
    "print(x[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f92326a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We can also use \":\" to select \"all\" of a target dimension\n",
    "x[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3caf5ff3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2, 5, 8]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Get all values of 0th and 1st dimensions but only index 1 of 2nd dimension\n",
    "x[:,:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e82338",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Get all values of the 0 dimension but only the 1 index value of 1st and 2nd dimension\n",
    "x[:,1,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3689ae05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Get index 0 of 0th and 1st dimension and all values of 2nd dimensions\n",
    "x[0,0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bafdea7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(9), tensor([9]))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0,2,2],x[:,2,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a86818c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([3, 6, 9]), tensor([[3, 6, 9]]))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0,:,2],x[:,:,2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87b32356",
   "metadata": {},
   "source": [
    "### PyTorch tensor & NumPy\n",
    "Numpy is a popular scientific Python numerical computing library and because of this, PyTorch has functionality to intract with it.\n",
    "* Data in NumPy, want in PyTorch tensor -> torch.from_numpy(ndarray)\n",
    "* PyTorch tensor -> NumPy -> torch.Tensro.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e30ae29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1., 2., 3., 4., 5., 6., 7.]),\n",
       " tensor([1., 2., 3., 4., 5., 6., 7.], dtype=torch.float64))"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "array = np.arange(1.0,8.0)\n",
    "#Warning: when converting from numpy -> pytorch, pytorch reflects numpy's default datatype of float64 unless specified otherwise.\n",
    "tensor = torch.from_numpy(array)\n",
    "array,tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bcfdffd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(dtype('float64'), torch.float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor = tensor.type(torch.float32)\n",
    "array.dtype,tensor.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47919264",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(dtype('float64'), torch.float64)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array.dtype,tensor.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cc989018",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-3.14159265, -3.13844949, -3.13530633, ...,  3.13530633,\n",
       "         3.13844949,  3.14159265]),\n",
       " array([-1.22464680e-16, -3.14315906e-03, -6.28628707e-03, ...,\n",
       "         6.28628707e-03,  3.14315906e-03,  1.22464680e-16]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "\n",
    "x = np.linspace(-math.pi,math.pi,2000)\n",
    "y = np.sin(x)\n",
    "\n",
    "x,y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b7b8742",
   "metadata": {},
   "source": [
    "### Reproducibility(trying to take random out of random)\n",
    "In short how a neural network learns:\n",
    "`start with random numbers -> tensor operations -> update random numbers to try and make them of the data -> again -> again -> again->`\n",
    "To reduce the randomness in the neural networks and PyTorch comes the concept of a random seed.\n",
    "Essentially what the random seed does is \"flavour\" the randomness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdbd2fae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3259, 0.9306, 0.8459, 0.6560],\n",
      "        [0.1116, 0.9726, 0.5772, 0.4115],\n",
      "        [0.0010, 0.4364, 0.2394, 0.4546]])\n",
      "tensor([[0.0509, 0.6389, 0.2446, 0.3497],\n",
      "        [0.4615, 0.3588, 0.4226, 0.4283],\n",
      "        [0.8974, 0.5865, 0.3292, 0.9636]])\n",
      "tensor([[False, False, False, False],\n",
      "        [False, False, False, False],\n",
      "        [False, False, False, False]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "#Creat two random tensors\n",
    "random_tensor_A = torch.rand(3,4)\n",
    "random_tensor_B = torch.rand(3,4)\n",
    "\n",
    "print(random_tensor_A)\n",
    "print(random_tensor_B)\n",
    "print(random_tensor_A==random_tensor_B)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "929e0866",
   "metadata": {},
   "source": [
    "Just as we might've expected, the tensors come out with different values.\n",
    "\n",
    "But what if we wanted to create two random tensors with the same values.\n",
    "\n",
    "As in, the tensors would still contain random values but they would be of the same flavour.\n",
    "\n",
    "That's where torch.manual_seed(seed) comes in, where seed is an integer (like 42 but it could be anything) that flavours the randomness.\n",
    "\n",
    "Let's try it out by creating some more flavoured random tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb2e817e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.8823, 0.9150, 0.3829, 0.9593],\n",
      "        [0.3904, 0.6009, 0.2566, 0.7936],\n",
      "        [0.9408, 0.1332, 0.9346, 0.5936]])\n",
      "tensor([[0.8823, 0.9150, 0.3829, 0.9593],\n",
      "        [0.3904, 0.6009, 0.2566, 0.7936],\n",
      "        [0.9408, 0.1332, 0.9346, 0.5936]])\n",
      "tensor([[True, True, True, True],\n",
      "        [True, True, True, True],\n",
      "        [True, True, True, True]])\n"
     ]
    }
   ],
   "source": [
    "#lets make some random but reproducable tensors\n",
    "#set the random seed.\n",
    "Random_seed = 42\n",
    "torch.manual_seed(Random_seed)\n",
    "random_tensor_C = torch.rand(3,4,device=\"cpu\")\n",
    "torch.manual_seed(Random_seed)\n",
    "random_tensor_D = torch.rand(3,4,device=\"cpu\")\n",
    "print(random_tensor_C)\n",
    "print(random_tensor_D)\n",
    "print(random_tensor_C==random_tensor_D)\n",
    "#All the random numbers can reproduce by random seed use torch.manual_seed before generating random tensor."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dd3109b",
   "metadata": {},
   "source": [
    "\n",
    "Nice!\n",
    "\n",
    "It looks like setting the seed worked.\n",
    "\n",
    "Resource: What we've just covered only scratches the surface of reproducibility in PyTorch. For more, on reproducibility in general and random seeds, I'd checkout:\n",
    "\n",
    "[The PyTorch reproducibility documentation](https://pytorch.org/docs/stable/notes/randomness.html) (a good exercise would be to read through this for 10-minutes and even if you don't understand it now, being aware of it is important).\n",
    "[The Wikipedia random seed page](https://en.wikipedia.org/wiki/Random_seed) (this'll give a good overview of random seeds and pseudorandomness in general)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a37b0d80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Jun 27 16:04:50 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 576.80                 Driver Version: 576.80         CUDA Version: 12.9     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                  Driver-Model | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce RTX 2050      WDDM  |   00000000:01:00.0 Off |                  N/A |\n",
      "| N/A   47C    P0              8W /   33W |       0MiB /   4096MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|  No running processes found                                                             |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f4e079e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdb950b6",
   "metadata": {},
   "source": [
    "## Running tensors and PyTorch on the GPUs (and making faster computations)\n",
    "GPUs = faster computation on numbers, thanks to CUDA(Nvidia hardware) + Pytorch working behind the scenes to make everything honky dory(good).\n",
    "\n",
    "To work with GPU we have three options:\n",
    "\n",
    "|Platform         |Iniial setup |Cost             |\n",
    "|-----------------|-------------|-----------------|\n",
    "|Google Colab     |Easy         |Freemium         |\n",
    "|Own Dedicated GPU|Medium       |One time purchase|\n",
    "|Cloud            |Medium       |Expensive        |\n",
    "\n",
    "For PyTorch its capable of running on the GPU or CPU, its best practice to setup device agnostic code:\n",
    "[Doumentaion for best practice.](https://docs.pytorch.org/docs/stable/notes/cuda.html#best-practices)\n",
    "\n",
    "Example: Run on GPU if available, else default to CPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfa7de74",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setup device for Agnostic Code(if GPU available runs on GPU else runs on CPU)\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e6da29",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor = torch.tensor([1,2,3])\n",
    "tensor_on_gpu = tensor.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af0f1eff",
   "metadata": {},
   "source": [
    "### Moving tensors back to the CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d0f1fe0",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#If tensors on GPU, can't transform to NumPy.\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mtensor_on_gpu\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mTypeError\u001b[0m: can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first."
     ]
    }
   ],
   "source": [
    "#If tensors on GPU, can't transform to NumPy.\n",
    "tensor_on_gpu.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef5eea35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3]\n"
     ]
    }
   ],
   "source": [
    "tensors_back_on_cpu = tensor_on_gpu.cpu().numpy()\n",
    "print(tensors_back_on_cpu)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
